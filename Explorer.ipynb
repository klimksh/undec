{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty in Software Architecture. Analisys of Apache Spark issue tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of issues:3122\n"
     ]
    }
   ],
   "source": [
    "from decisions import connect_to_mongo, get_decisions_filtered\n",
    "db = connect_to_mongo()\n",
    "decisions = get_decisions_filtered(db)\n",
    "print(\"Total number of issues:%d\"%(len(decisions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = [d for d in decisions if \"description_annotations\" in [key for key, value in d.items()]] \n",
    "print(\"Total number of issues annotated:%d\"%len(decisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in decisions:\n",
    "    d[\"number_of_uncertainties\"] = 0\n",
    "    d[\"uncertainties\"] = dict()\n",
    "    for annotation in d.get(\"description_annotations\"):\n",
    "        if annotation[\"ner\"]==\"UNCERTAINTY\":\n",
    "            d[\"number_of_uncertainties\"] += 1 \n",
    "            try: \n",
    "                d[\"uncertainties\"][annotation[\"token\"]] += 1\n",
    "            except KeyError as e:\n",
    "                d[\"uncertainties\"].update({annotation[\"token\"] : 1})\n",
    "    print(d[\"key\"],d[\"number_of_uncertainties\"],d[\"fields\"][\"issuetype\"][\"name\"], d[\"uncertainties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max number of uncertainties in one issue\", max([d[\"number_of_uncertainties\"] for d in decisions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncers_by_issue_type = dict()\n",
    "number_of_issues_with_uncer = dict()\n",
    "total_uncers_by_issue_type = dict()\n",
    "for d in decisions:\n",
    "    try: \n",
    "        uncers_by_issue_type[d['fields']['issuetype']['name']] += d[\"number_of_uncertainties\"]\n",
    "        number_of_issues_with_uncer[d['fields']['issuetype']['name']] += 1 if d[\"number_of_uncertainties\"] > 0 else 0\n",
    "        total_uncers_by_issue_type[d['fields']['issuetype']['name']] += 1\n",
    "    except KeyError as e:\n",
    "        uncers_by_issue_type.update({d['fields']['issuetype']['name'] : d[\"number_of_uncertainties\"]})\n",
    "        number_of_issues_with_uncer.update({d['fields']['issuetype']['name'] : 1 if d[\"number_of_uncertainties\"] > 0 else 0})\n",
    "        total_uncers_by_issue_type.update({d['fields']['issuetype']['name'] : 1})        \n",
    "\n",
    "# print(\"Total number of issues by issue type:\")\n",
    "# print(total_by_issue_type)\n",
    "\n",
    "print(\"Number of issues that has at least one uncertainty:\")\n",
    "print(number_of_issues_with_uncer)\n",
    "\n",
    "print(\"Number of uncertainties by issue type:\")\n",
    "print(uncers_by_issue_type)\n",
    "\n",
    "# print(\"Ratio of uncertainty per issue type\")\n",
    "# for key,value in total_by_issue_type.items():\n",
    "#     print(\"%s:%.2f\"%(key,number_of_issues_with_uncer[key]/value*100))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of uncertainties\")\n",
    "print (sum([d[\"number_of_uncertainties\"] for d in decisions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision title: Allow IPv6 address in org.apache.spark.util.Utils.parseHostPort \n",
      "Decision link: https://issues.apache.org/jira/browse/SPARK-22180\n",
      "Description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">External applications like Apache Cassandra are able to deal with IPv6 addresses. Libraries like spark-cassandra-connector combine Apache Cassandra with Apache Spark.\r",
       "</br>This combination is very useful  IMHO. \r\n",
       "\r\n",
       "One problem is that  {code:java} org.apache.spark.util.Utils.parseHostPort(hostPort: String) {code} takes the last colon to sepperate the port from host path. This conflicts with literal IPv6 addresses.\r\n",
       "\r\n",
       "I \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    think\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">UNCERTAINTY</span>\n",
       "</mark>\n",
       " we can take {code}hostPort{code} as literal IPv6 address if it contains tow ore more colons. If IPv6 addresses are enclosed in square brackets port definition is still \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    possible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">UNCERTAINTY</span>\n",
       "</mark>\n",
       ".\r\n",
       "\r\n",
       "\r\n",
       "\r\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import discoverer\n",
    "\n",
    "uncertainties = [\n",
    "    \"think\", \"thought\", \"thinking\", \"almost\", \n",
    "    \"apparent\", \"apparently\", \"appear\", \"appeared\", \"appears\", \"approximately\", \"around\",\n",
    "    \"assume\", \"assumed\", \"certain amount\", \"certain extent\", \"certain level\", \"claim\",\n",
    "    \"claimed\", \"doubt\", \"doubtful\", \"essentially\", \"estimate\",\n",
    "    \"estimated\", \"feel\", \"felt\", \"frequently\", \"from our perspective\", \"generally\", \"guess\",\n",
    "    \"in general\", \"in most cases\", \"in most instances\", \"in our view\", \"indicate\", \"indicated\",\n",
    "    \"largely\", \"likely\", \"mainly\", \"may\", \"maybe\", \"might\", \"mostly\", \"often\", \"on the whole\",\n",
    "    \"ought\", \"perhaps\", \"plausible\", \"plausibly\", \"possible\", \"possibly\", \"postulate\",\n",
    "    \"postulated\", \"presumable\", \"probable\", \"probably\", \"relatively\", \"roughly\", \"seems\",\n",
    "    \"should\", \"sometimes\", \"somewhat\", \"suggest\", \"suggested\", \"suppose\", \"suspect\", \"tend to\",\n",
    "    \"tends to\", \"typical\", \"typically\", \"uncertain\", \"uncertainly\", \"unclear\", \"unclearly\",\n",
    "    \"unlikely\", \"usually\", \"broadly\", \"tended to\", \"presumably\", \"suggests\",\n",
    "    \"from this perspective\", \"from my perspective\", \"in my view\", \"in this view\", \"in our opinion\",\n",
    "    \"in my opinion\", \"to my knowledge\", \"fairly\", \"quite\", \"rather\", \"argue\", \"argues\", \"argued\",\n",
    "    \"claims\", \"feels\", \"indicates\", \"supposed\", \"supposes\", \"suspects\", \"postulates\"\n",
    "]\n",
    "ents = ['UNCERTAINTY']\n",
    "decision = [d for d in decisions if d['key']=='SPARK-22180'][0]\n",
    "\n",
    "print(\"Decision title: %s \\nDecision link: https://issues.apache.org/jira/browse/%s\"%(decision['fields']['summary'], decision['key']))\n",
    "\n",
    "print(\"Description:\")\n",
    "discoverer.main(decision['fields']['description'], *uncertainties, ents=ents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comments:\")\n",
    "for key, val in enumerate(decision['comments']):\n",
    "    print(\"Comment %d (Author: %s)\"%(key, val['author']['name']))\n",
    "    print(discoverer.main(val['body'], *uncertainties, ents=ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(\"test\")\n",
    "wb.save('balances.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
